{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "\n",
    "class DataSpliter(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dataframe, features, labels):\n",
    "        'Initialization'\n",
    "        super(DataSpliter, self).__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.labels = labels\n",
    "        self.list_IDs = features\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.dataframe.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        X = torch.FloatTensor(self.dataframe[self.list_IDs].to_numpy())[index]\n",
    "        y = (torch.LongTensor(self.dataframe[self.labels].to_numpy())).squeeze(1)[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth            Name\n",
       "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris = pd.get_dummies(iris)\n",
    "# iris.columns\n",
    "mappings = {\n",
    "   'Iris-setosa': 0,\n",
    "   'Iris-versicolor': 1,\n",
    "   'Iris-virginica': 2\n",
    "}\n",
    "iris['Name'] = iris['Name'].apply(lambda x: mappings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5), (30, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_limit = int(iris.shape[0]*.8)\n",
    "iris_train = iris[:test_limit]\n",
    "iris_test = iris[test_limit:]\n",
    "iris_train.shape, iris_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = DataSpliter(iris_train, ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], ['Name'])\n",
    "# X_train = iris_data[:][0]\n",
    "# y_train = iris_data[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 50,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = data.DataLoader(iris_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=4, out_features=16)\n",
    "        self.fc2 = nn.Linear(in_features=16, out_features=12)\n",
    "        self.output = nn.Linear(in_features=12, out_features=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANN2(\n",
       "  (fc1): Linear(in_features=4, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=12, bias=True)\n",
       "  (output): Linear(in_features=12, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ANN2()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = training_generator.__iter__().next()\n",
    "# y_hat = model.forward(x_train)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.1114628314971924\n",
      "Epoch: 10 Loss: 0.7137932777404785\n",
      "Epoch: 20 Loss: 0.4906112551689148\n",
      "Epoch: 30 Loss: 0.31363537907600403\n",
      "Epoch: 40 Loss: 0.36875590682029724\n",
      "Epoch: 50 Loss: 0.2983701825141907\n",
      "Epoch: 60 Loss: 0.17003491520881653\n",
      "Epoch: 70 Loss: 0.2154860496520996\n",
      "Epoch: 80 Loss: 0.19274850189685822\n",
      "Epoch: 90 Loss: 0.15811702609062195\n",
      "Epoch: 100 Loss: 0.20718666911125183\n",
      "Epoch: 110 Loss: 0.053132735192775726\n",
      "Epoch: 120 Loss: 0.10098382085561752\n",
      "Epoch: 130 Loss: 0.04496880620718002\n",
      "Epoch: 140 Loss: 0.03777848929166794\n",
      "Epoch: 150 Loss: 0.07400967180728912\n",
      "Epoch: 160 Loss: 0.16549734771251678\n",
      "Epoch: 170 Loss: 0.050620187073946\n",
      "Epoch: 180 Loss: 0.015123116783797741\n",
      "Epoch: 190 Loss: 0.018933163955807686\n",
      "Epoch: 200 Loss: 0.01657499559223652\n",
      "Epoch: 210 Loss: 0.008309027180075645\n",
      "Epoch: 220 Loss: 0.057054053992033005\n",
      "Epoch: 230 Loss: 0.01956889033317566\n",
      "Epoch: 240 Loss: 0.021948207169771194\n",
      "Epoch: 250 Loss: 0.027825143188238144\n",
      "Epoch: 260 Loss: 0.022910604253411293\n",
      "Epoch: 270 Loss: 0.014848873019218445\n",
      "Epoch: 280 Loss: 0.0768715888261795\n",
      "Epoch: 290 Loss: 0.1874960958957672\n",
      "Epoch: 300 Loss: 0.004933994263410568\n",
      "Epoch: 310 Loss: 0.049639418721199036\n",
      "Epoch: 320 Loss: 0.014487502165138721\n",
      "Epoch: 330 Loss: 0.14053237438201904\n",
      "Epoch: 340 Loss: 0.04029930382966995\n",
      "Epoch: 350 Loss: 0.08122407644987106\n",
      "Epoch: 360 Loss: 0.007420683745294809\n",
      "Epoch: 370 Loss: 0.00409299973398447\n",
      "Epoch: 380 Loss: 0.0826224535703659\n",
      "Epoch: 390 Loss: 0.0332721509039402\n",
      "Epoch: 400 Loss: 0.047247208654880524\n",
      "Epoch: 410 Loss: 0.12257619202136993\n",
      "Epoch: 420 Loss: 0.0040602125227451324\n",
      "Epoch: 430 Loss: 0.08617407083511353\n",
      "Epoch: 440 Loss: 0.02117828279733658\n",
      "Epoch: 450 Loss: 0.07022322714328766\n",
      "Epoch: 460 Loss: 0.001052191248163581\n",
      "Epoch: 470 Loss: 0.047886550426483154\n",
      "Epoch: 480 Loss: 0.01570180617272854\n",
      "Epoch: 490 Loss: 0.033712729811668396\n",
      "CPU times: user 4.4 s, sys: 6.8 s, total: 11.2 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 500\n",
    "loss_arr = []\n",
    "for i in range(epochs):\n",
    "    for x_train, y_train in training_generator:\n",
    "        y_hat = model.forward(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss_arr.append(loss)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} Loss: {loss}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 4]), torch.Size([30]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris2_data2 = DataSpliter(iris_test, ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], ['Name'])\n",
    "X_test = iris2_data2[:][0]\n",
    "y_test = iris2_data2[:][1]\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for val in X_test:\n",
    "        y_hat = model.forward(val)\n",
    "        preds.append(y_hat.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>YHat</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y  YHat  Correct\n",
       "0   2     2        1\n",
       "1   2     2        1\n",
       "2   2     2        1\n",
       "3   2     2        1\n",
       "4   2     2        1\n",
       "5   2     2        1\n",
       "6   2     2        1\n",
       "7   2     2        1\n",
       "8   2     2        1\n",
       "9   2     2        1\n",
       "10  2     2        1\n",
       "11  2     2        1\n",
       "12  2     2        1\n",
       "13  2     1        0\n",
       "14  2     2        1\n",
       "15  2     2        1\n",
       "16  2     2        1\n",
       "17  2     2        1\n",
       "18  2     2        1\n",
       "19  2     2        1\n",
       "20  2     2        1\n",
       "21  2     2        1\n",
       "22  2     2        1\n",
       "23  2     2        1\n",
       "24  2     2        1\n",
       "25  2     2        1\n",
       "26  2     2        1\n",
       "27  2     2        1\n",
       "28  2     2        1\n",
       "29  2     2        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Y': y_test, 'YHat': preds})\n",
    "df['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df['Y'], df['YHat'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Correct'].sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3981,  0.0284,  0.6853,  1.0698],\n",
      "        [-0.4069,  0.3903, -0.2666,  0.0922],\n",
      "        [ 0.5218,  0.8250, -0.6306, -1.2016],\n",
      "        [ 0.1355, -0.3274, -0.3597,  0.3076],\n",
      "        [ 0.0905,  0.7467, -0.5504, -0.2572],\n",
      "        [ 0.4317,  0.4432, -0.6113, -0.3963],\n",
      "        [ 0.2185, -0.4803, -0.2054, -0.4129],\n",
      "        [-0.0892, -0.3914, -0.0059,  0.0577],\n",
      "        [ 0.0868,  0.2976,  0.4204, -0.2102],\n",
      "        [ 0.3062, -0.6850,  0.5834,  0.8635],\n",
      "        [-0.1052, -0.1982, -0.4827, -0.0628],\n",
      "        [ 0.5467, -0.1497, -0.2590, -0.2893],\n",
      "        [-0.2253,  0.2552,  0.1119,  0.8226],\n",
      "        [-0.3253, -0.1027, -0.3014,  0.4747],\n",
      "        [ 0.5194,  0.4075, -0.4612, -0.9260],\n",
      "        [ 0.4818,  0.4820, -0.2426, -0.6389]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6623, -0.0366,  1.0087,  0.3035,  0.9934,  0.1348, -0.2848,  0.1284,\n",
      "         0.3562, -0.7707, -0.0982,  0.2602, -0.4431,  0.4155,  0.0178, -0.0033],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.9551e-01,  6.1982e-02, -6.0636e-01, -2.0432e-01,  6.2112e-02,\n",
      "         -3.6071e-01,  5.4104e-02,  1.9235e-01,  6.1749e-02,  3.8238e-01,\n",
      "         -5.2725e-02, -3.9473e-03,  8.0500e-01, -9.2221e-02, -6.9978e-01,\n",
      "         -1.8338e-01],\n",
      "        [-7.1531e-02, -1.0131e-01, -3.7060e-02, -1.9370e-01, -2.4059e-01,\n",
      "         -2.1647e-01,  2.7812e-02, -1.0622e-01, -1.0361e-01,  1.5638e-01,\n",
      "          5.4189e-02,  7.9566e-02, -2.4037e-01,  1.4329e-01,  1.5903e-01,\n",
      "         -5.0470e-02],\n",
      "        [-2.9764e-01, -8.4864e-02,  1.0220e+00, -7.0577e-02,  8.0064e-01,\n",
      "          8.4927e-01, -6.2212e-02,  9.2178e-02,  2.5471e-01, -5.6903e-01,\n",
      "          9.7113e-02,  2.3427e-01, -2.9778e-01,  8.5612e-02,  7.6357e-01,\n",
      "          5.1240e-01],\n",
      "        [-8.7326e-05, -2.4694e-01,  8.9297e-02,  1.2526e-01, -2.0466e-01,\n",
      "         -1.9338e-02,  9.2756e-02,  9.4191e-02,  4.4189e-02,  3.9820e-02,\n",
      "         -1.7105e-01, -2.0171e-01, -3.0120e-01,  2.3884e-01,  3.3706e-02,\n",
      "         -2.0274e-01],\n",
      "        [ 7.5484e-02,  3.4617e-02, -1.4863e-01,  1.7492e-01,  2.7314e-02,\n",
      "         -1.6661e-01,  2.5263e-02, -2.1673e-01,  1.5795e-01, -1.3731e-01,\n",
      "          1.4825e-01, -2.8705e-01, -7.7227e-02, -2.4916e-01,  1.6766e-01,\n",
      "         -1.1849e-01],\n",
      "        [ 4.6039e-01,  1.4279e-01, -2.3575e-02, -1.0258e-01, -4.1024e-01,\n",
      "         -3.9534e-01, -1.5860e-01,  9.8984e-02,  4.8143e-01,  3.0961e-01,\n",
      "          5.7115e-02,  3.6568e-01, -6.5463e-03,  1.2807e-01, -2.6978e-01,\n",
      "         -1.4497e-01],\n",
      "        [-1.7825e-01,  5.5556e-02, -9.6732e-02,  1.3227e-01, -3.0680e-02,\n",
      "         -7.4772e-02, -8.3548e-02,  1.3976e-01, -2.4529e-01, -1.8476e-01,\n",
      "          2.4864e-01,  2.4900e-01, -5.4504e-02,  2.4989e-01, -6.4024e-02,\n",
      "         -3.1254e-02],\n",
      "        [ 2.8466e-01, -5.1093e-02, -9.2019e-01, -1.1999e-01, -3.4368e-01,\n",
      "         -1.1556e+00,  2.0079e-01, -1.3452e-01,  2.6068e-01,  4.5446e-01,\n",
      "         -1.8762e-01, -3.2969e-02,  4.8616e-01,  9.0501e-02, -6.0722e-01,\n",
      "          1.0311e-02],\n",
      "        [ 4.2837e-01,  4.8816e-02,  2.4976e-01, -6.7422e-02, -7.3250e-01,\n",
      "         -4.7737e-01, -2.2895e-01, -2.1351e-01,  4.3103e-01,  3.3593e-01,\n",
      "         -1.6680e-01,  1.1843e-01, -2.0762e-01,  1.6002e-01, -1.8372e-02,\n",
      "         -3.5378e-02],\n",
      "        [ 2.4073e-02,  4.7820e-02, -1.8666e-01,  4.0018e-02,  2.3760e-01,\n",
      "         -2.0159e-02,  2.3495e-01, -1.4021e-01, -1.8125e-01,  6.9151e-02,\n",
      "          1.5950e-01,  1.3747e-01, -1.5463e-01,  1.6206e-01, -6.4467e-02,\n",
      "         -1.6126e-01],\n",
      "        [-1.9721e-01, -1.0498e-01,  1.2959e-01,  9.1957e-02,  1.3692e-01,\n",
      "         -9.5533e-02, -2.0793e-01, -1.3888e-02,  5.9744e-03,  9.5197e-02,\n",
      "         -1.0981e-01, -1.9590e-01, -3.3395e-02,  1.4677e-01, -6.4589e-02,\n",
      "         -1.1130e-01],\n",
      "        [ 3.0294e-01,  1.2971e-01, -1.6330e-01, -1.6303e-01, -2.1946e-03,\n",
      "          9.1793e-02, -1.4307e-01, -1.3742e-01,  9.7989e-02, -1.7317e-01,\n",
      "          1.0141e-02, -1.0586e-01,  4.0731e-01,  5.8073e-02,  5.0301e-03,\n",
      "         -8.2416e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2346, -0.1999,  0.6317, -0.2797, -0.1403,  0.2542,  0.1457, -0.5325,\n",
      "         0.4504, -0.2178,  0.0635, -0.2284], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.0751, -0.1499,  0.8342,  0.0443, -0.3575, -0.9023, -0.0933, -0.4768,\n",
      "         -0.9330, -0.0513,  0.0886, -1.4806],\n",
      "        [-0.1068,  0.2267,  0.2104,  0.1489,  0.1030,  0.0710, -0.2397, -0.6244,\n",
      "          0.2882,  0.2157,  0.1822, -0.0499],\n",
      "        [ 0.5680, -0.0190, -1.2932,  0.2057, -0.1663,  0.1130,  0.2340,  0.6552,\n",
      "          0.1212,  0.0216, -0.0209,  0.0679]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1343,  0.4414, -0.2249], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for coeff in model.parameters():\n",
    "    print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
