{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "iris_main = pd.read_csv('https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepalLength    float64\n",
       "SepalWidth     float64\n",
       "PetalLength    float64\n",
       "PetalWidth     float64\n",
       "Name            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = iris_main.copy()\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth             Name\n",
       "120          6.9         3.2          5.7         2.3   Iris-virginica\n",
       "41           4.5         2.3          1.3         0.3      Iris-setosa\n",
       "44           5.1         3.8          1.9         0.4      Iris-setosa\n",
       "91           6.1         3.0          4.6         1.4  Iris-versicolor\n",
       "5            5.4         3.9          1.7         0.4      Iris-setosa\n",
       "56           6.3         3.3          4.7         1.6  Iris-versicolor\n",
       "78           6.0         2.9          4.5         1.5  Iris-versicolor\n",
       "137          6.4         3.1          5.5         1.8   Iris-virginica\n",
       "49           5.0         3.3          1.4         0.2      Iris-setosa\n",
       "20           5.4         3.4          1.7         0.2      Iris-setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_table(dataframe):\n",
    "    mean_std_dict = {}\n",
    "    for each_column, each_dtype in zip(iris.columns, iris.dtypes):\n",
    "        if each_dtype == 'float64':\n",
    "            column_mean = iris[each_column].mean()\n",
    "            column_std = iris[each_column].std()\n",
    "            mean_std_dict[each_column] = column_mean, column_std\n",
    "            dataframe[each_column] = (dataframe[each_column]- column_mean)/(column_std**2)\n",
    "    return mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SepalLength': (5.843333333333335, 0.8280661279778629),\n",
       " 'SepalWidth': (3.0540000000000007, 0.4335943113621737),\n",
       " 'PetalLength': (3.7586666666666693, 1.7644204199522617),\n",
       " 'PetalWidth': (1.1986666666666672, 0.7631607417008414)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stats_dict = mean_std_table(iris)\n",
    "my_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def my_hot_encoding(dataframe, feature_list_to_encode):\n",
    "    encoding_dict = {}\n",
    "    for each_feature in feature_list_to_encode:\n",
    "        feature_dict = {}\n",
    "        for index_type, each_type in enumerate(dataframe[each_feature].unique()):\n",
    "            feature_dict[each_type] = index_type\n",
    "        encoding_dict[each_feature] = feature_dict\n",
    "    for each_feature in feature_list_to_encode:\n",
    "        dataframe[each_feature] = dataframe[each_feature].map(lambda x: encoding_dict[each_feature][x])\n",
    "    dataframe[each_feature].astype(np.int64)\n",
    "    return encoding_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_discrete_dict = my_hot_encoding(iris, ['Name'])\n",
    "my_discrete_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_distribution(dataframe: pd, label, my_sample_number=5, shuffle=True):\n",
    "    value_count_output = dataframe[label].value_counts()\n",
    "    if my_sample_number <= value_count_output.min():\n",
    "        unique_output_dict = value_count_output.to_dict()\n",
    "        dataframe_train_list = [dataframe[dataframe[label] == each_outcome].sample(my_sample_number) for each_outcome in unique_output_dict]\n",
    "        if shuffle:\n",
    "            dataframe_train_df = pd.concat(dataframe_train_list).sample(frac=1).copy()\n",
    "        else:\n",
    "            dataframe_train_df = pd.concat(dataframe_train_list)\n",
    "        dataframe_test_df = dataframe.drop(dataframe_train_df.index).copy()\n",
    "        return dataframe_train_df, dataframe_test_df\n",
    "    else:\n",
    "        print(value_count_output)\n",
    "        print(dataframe.shape)\n",
    "        print('Resorting to normal output')\n",
    "#         assert my_sample_number > dataframe.shape[0]\n",
    "        if shuffle:\n",
    "            dataframe_train_df = dataframe.sample(my_sample_number).copy()\n",
    "        else:\n",
    "            dataframe_train_df = dataframe.head(my_sample_number).copy()\n",
    "    return dataframe_train_df, dataframe.drop(dataframe_train_df.index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: Name, dtype: int64\n",
      "(150, 5)\n",
      "Resorting to normal output\n"
     ]
    }
   ],
   "source": [
    "X_train_iris, y_test_iris = even_distribution(iris, 'Name', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 5), (90, 5))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_iris.shape, y_test_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.521574</td>\n",
       "      <td>-0.287228</td>\n",
       "      <td>-0.757639</td>\n",
       "      <td>-1.543002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-1.375736</td>\n",
       "      <td>-2.946745</td>\n",
       "      <td>0.238127</td>\n",
       "      <td>0.860785</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.665992</td>\n",
       "      <td>1.308483</td>\n",
       "      <td>0.719950</td>\n",
       "      <td>2.234377</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.374317</td>\n",
       "      <td>-1.351035</td>\n",
       "      <td>0.302370</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-2.104925</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>-0.789761</td>\n",
       "      <td>-1.714701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  Name\n",
       "45     -1.521574   -0.287228    -0.757639   -1.543002     0\n",
       "106    -1.375736   -2.946745     0.238127    0.860785     2\n",
       "100     0.665992    1.308483     0.719950    2.234377     2\n",
       "73      0.374317   -1.351035     0.302370    0.002289     1\n",
       "42     -2.104925    0.776579    -0.789761   -1.714701     0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_tr = torch.tensor(X_train_iris.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 7,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 2}\n",
    "training_generator = data.DataLoader(iris_tr, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3757, -2.9467,  0.2381,  0.8608,  2.0000],\n",
       "        [ 1.9785, -0.2872,  0.6557,  0.6891,  2.0000],\n",
       "        [ 1.2493, -2.9467,  0.6557,  1.0325,  2.0000],\n",
       "        [ 0.5202, -0.8191,  0.1739,  0.1740,  1.0000],\n",
       "        [ 0.2285, -0.2872,  0.3345,  1.0325,  2.0000],\n",
       "        [ 0.9577, -0.2872,  0.6557,  1.7193,  2.0000],\n",
       "        [-0.2090, -1.3510,  0.1096,  0.1740,  1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy = training_generator.__iter__().next()\n",
    "# dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 0, 0, 2, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy[:,-1].type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3894, 0.1339, 0.0220],\n",
       "         [0.9231, 0.3532, 0.4501],\n",
       "         [0.5169, 0.4078, 0.2602],\n",
       "         [0.6727, 0.2713, 0.5925]], requires_grad=True),\n",
       " tensor([0.0497], requires_grad=True))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w = torch.rand(dim, requires_grad=True)\n",
    "w = torch.rand(4,3, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.9591, -4.0106, -0.7898, -1.5430],\n",
       "         [ 0.3743, -2.4148,  0.5915,  0.3457],\n",
       "         [-0.2090, -2.4148, -0.0831, -0.3411],\n",
       "         [-2.2508, -0.2872, -0.8540, -1.8864],\n",
       "         [-1.3757,  0.2447, -0.7255, -1.8864],\n",
       "         [ 2.5619, -0.2872,  0.9127,  1.5476],\n",
       "         [-1.0841,  1.8404, -0.7255, -1.7147]], dtype=torch.float64),\n",
       " tensor([[0.3894, 0.1339, 0.0220],\n",
       "         [0.9231, 0.3532, 0.4501],\n",
       "         [0.5169, 0.4078, 0.2602],\n",
       "         [0.6727, 0.2713, 0.5925]], requires_grad=True))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = dummy[:,0:-1]\n",
    "sample_batch, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.9113, -2.4194, -2.9679],\n",
       "         [-1.5452, -0.4678, -0.7200],\n",
       "         [-2.5830, -1.0073, -1.3153],\n",
       "         [-2.8519, -1.2628, -1.5186],\n",
       "         [-1.9537, -0.9054, -1.2265],\n",
       "         [ 2.2451,  1.0336,  1.0814],\n",
       "         [-0.2516, -0.2562, -0.4002]], dtype=torch.float64,\n",
       "        grad_fn=<MmBackward>),\n",
       " torch.Size([7, 3]))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.matmul(sample_batch, w.type(torch.float64))\n",
    "y_hat, y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7676, dtype=torch.float64, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49390842/cross-entropy-in-pytorch\n",
    "loss = criterion(y_hat, y_actual.type(torch.LongTensor))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 0, 0, 2, 0])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7676, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss\n",
    "my_sum = 0\n",
    "for index, value in enumerate(y_actual.type(torch.IntTensor)):\n",
    "    my_sum += y_hat[index, value]*-1 + torch.log(torch.exp(y_hat[index]).sum())\n",
    "print(my_sum/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(y_hat, y_actual):\n",
    "    my_sum = 0\n",
    "    for index, value in enumerate(y_actual.type(torch.IntTensor)):\n",
    "        my_sum += y_hat[index, value]*-1 + torch.log(torch.exp(y_hat[index]).sum())\n",
    "    return my_sum/y_hat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6673, 0.3759, 0.0758],\n",
       "         [0.5282, 0.0964, 0.6912],\n",
       "         [0.2048, 0.8031, 0.7101],\n",
       "         [0.7284, 0.2818, 0.9685]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.3194], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size = torch.tensor(.0001)\n",
    "num_epochs = 5000\n",
    "minibatch_size = 20\n",
    "w = torch.rand(4,3, requires_grad=True, dtype=torch.float64)\n",
    "b = torch.rand(1, requires_grad=True, dtype=torch.float64)\n",
    "w, b\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'criterion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b6e96f9e582b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
     ]
    }
   ],
   "source": [
    "# torchvariable.to(device)\n",
    "# model.to(device) Class instances can go into CUDA too\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "x_test_tensor = x_test_tensor.to(device)\n",
    "\n",
    "Y_train_tensor = Y_train_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8294, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.9489, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.0555, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.1955, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7960, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5790, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.9364, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6926, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3345, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5476, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5908, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3524, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7636, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7115, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2724, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7149, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3455, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5328, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2249, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2833, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7679, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4320, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3490, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1809, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4652, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.1032, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.9007, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5186, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2587, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5550, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6035, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5439, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5994, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5093, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.7032, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2447, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2811, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.1096, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6363, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3681, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1797, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3205, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2865, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3283, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2488, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2592, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4050, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2371, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2134, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3060, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3339, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6859, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6811, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2924, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2623, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1896, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2887, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2702, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3189, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2618, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1842, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.5264, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.0850, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4215, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3364, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.9215, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.2714, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.8399, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.0334, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.6861, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1512, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1372, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.3036, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(1.2651, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.1303, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.0440, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.0286, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.0330, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(0.4390, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-955754d99fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         loss = criterion(y_hat, batch[:,-1].type(torch.LongTensor)) #average loss per batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# has data or is still active\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "loss_arr = []\n",
    "for i in range(epochs):\n",
    "    for batch in training_generator:\n",
    "        y_hat = torch.matmul(batch[:,:-1], w) + b\n",
    "#         loss = criterion(y_hat, batch[:,-1].type(torch.LongTensor)) #average loss per batch\n",
    "        loss = my_loss(y_hat, batch[:,-1].type(torch.LongTensor))\n",
    "        loss_arr.append(loss)\n",
    "        loss.backward()\n",
    "        w.data -= step_size * w.grad.data\n",
    "        b.data -= step_size * b.grad.data\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    if i % 25 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "with torch.no_grad():\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  outputs = model(x_test_tensor)\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "  y_test = y_test_tensor.cpu().numpy()\n",
    "  predicted = predicted.cpu()\n",
    "\n",
    "  print(\"Accuracy: \", accuracy_score(predicted, y_test))\n",
    "  print(\"Precision: \", precision_score(predicted, y_test, average='weighted'))\n",
    "  print(\"Recall: \", recall_score(predicted, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "  pickle.dump(model, file)\n",
    "files.download('model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python361064bitbaseconda781f63433f6e4e048d2f76097806863c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
