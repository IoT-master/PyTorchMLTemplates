{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/senhmo/anaconda3/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (4.44.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (1.17.4)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (42.0.1.post20191125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/bentrevett/pytorch-sentiment-analysis\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.17.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (42.0.1.post20191125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.44.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/senhmo/anaconda3/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/senhmo/anaconda3/lib/python3.6/site-packages/en_core_web_sm -->\n",
      "/Users/senhmo/anaconda3/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://thicknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/\n",
    "tweets = pd.read_csv('datasets/tweets/tweets.csv', error_bad_lines = False)\n",
    "tweets = tweets.head(5000)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0                       is so sad for my APL frie...\n",
       "1          0                     I missed the New Moon trail...\n",
       "2          1                            omg its already 7:30 :O\n",
       "3          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(columns = ['ItemID', 'SentimentSource'], axis =1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3555\n",
       "1    1445\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Labels')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
    "ax.set(xlabel='Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(tweets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Sentiment                                      SentimentText\n",
       " 0             0      My sunglasses are full of Ben&amp;JerryÂ´s !!\n",
       " 1             1                Sleepy time after Men vs Wild.&lt;3\n",
       " 2             0                             but I love you, Aaron.\n",
       " 3             0                            i've lost my clearways.\n",
       " 4             1   yeps! )) that was amazing! xD finally somethi...\n",
       " ...         ...                                                ...\n",
       " 3995          1   partying with the home dogs. Lmao and mark he...\n",
       " 3996          1                 ahh school on monday!!!! not ready\n",
       " 3997          0            I want LinesVines and trying times now \n",
       " 3998          0   Joseph Adam Jonas! You keep a smile on my fac...\n",
       " 3999          0   Dinara lost again in Roland Garros. Why the S...\n",
       " \n",
       " [4000 rows x 2 columns],\n",
       "      Sentiment                                      SentimentText\n",
       " 0            0                       but theres always tomorrow..\n",
       " 1            1   I get to sleep in as late as I want tomorrow!...\n",
       " 2            0   I hate muscle spasms. Fuck you spasms!!!!! ht...\n",
       " 3            1   _BellaCullen18_  i've been ok just got throug...\n",
       " 4            1  - @breegeek I'll know if u can't find a replac...\n",
       " ..         ...                                                ...\n",
       " 995          0           SOME SAAAAAAAAAAAAAAAAAAAAY I WALK ALONE\n",
       " 996          1   is not a face, it's the scalp of a cat, with ...\n",
       " 997          0                     idk if i should have said that\n",
       " 998          1   i have an idea im going to get a gun go to ta...\n",
       " 999          1   Found a place to buy Secret Agent Sam. Now wh...\n",
       " \n",
       " [1000 rows x 2 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('datasets/tweets/train_tweets.csv', index=False)\n",
    "test.to_csv('datasets/tweets/test_tweets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tweets.csv  train_tweets.csv tweets.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls datasets/tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = re.sub(r'https?:/\\/\\S+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s):\n",
    "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize=tokenizer)\n",
    "LABEL = torchtext.data.Field(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [('Sentiment', LABEL), ('SentimentText', TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, tst = torchtext.data.TabularDataset.splits(path = 'datasets/tweets/',\n",
    "                                               train = 'train_tweets.csv',\n",
    "                                               test = 'test_tweets.csv',\n",
    "                                               format = 'csv',\n",
    "                                               skip_header = True,\n",
    "                                               fields = datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4000\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(trn)}')\n",
    "print(f'Number of testing examples: {len(tst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': ['0'],\n",
       " 'SentimentText': ['my',\n",
       "  'sunglasses',\n",
       "  'are',\n",
       "  'full',\n",
       "  'of',\n",
       "  'ben',\n",
       "  'amp',\n",
       "  'jerry',\n",
       "  's']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trn.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, max_size=25000,\n",
    "                vectors=\"glove.6B.100d\",\n",
    "                unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 2584), ('to', 1242), ('the', 1028), ('my', 938), ('a', 821), ('and', 645), ('it', 550), ('is', 540), ('m', 507), ('in', 467), ('t', 450), ('of', 410), ('me', 396), ('for', 394), ('s', 391), ('you', 390), ('on', 389), ('so', 348), ('this', 312), ('that', 308), ('have', 305), ('just', 270), ('at', 261), ('not', 260), ('http', 258), ('be', 250), ('but', 231), ('now', 223), ('all', 220), ('with', 211), ('can', 210), ('day', 206), ('nt', 204), ('quot', 201), ('up', 198), ('out', 198), ('get', 196), ('do', 190), ('was', 186), ('no', 183), ('like', 176), ('go', 175), ('good', 168), ('amp', 158), ('today', 155), ('got', 148), ('are', 147), ('3', 145), ('want', 145), ('one', 142)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'i', 'to', 'the', 'my', 'a', 'and', 'it', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1a2461ef98>>, {'<unk>': 0, '<pad>': 1, '0': 2, '1': 3})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "                                (trn, tst),\n",
    "                                batch_size =64,\n",
    "                                sort_key= lambda x: len(x.SentimentText),\n",
    "                                sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Gated Recurrent Unit\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim =1))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(8050, 100)\n",
       "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8050, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0872, -0.4708,  1.1398,  ..., -0.0552, -2.5647, -0.5852],\n",
       "        [ 0.3873,  0.9181,  0.6485,  ..., -0.8814, -1.7192, -0.7085],\n",
       "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
       "        ...,\n",
       "        [-0.5583,  0.3698, -1.2978,  ..., -0.2742, -0.5310,  0.2084],\n",
       "        [-0.2372, -0.3621,  0.8482,  ...,  0.6932,  1.7314,  1.0317],\n",
       "        [ 0.4593,  0.0251,  0.0319,  ..., -0.0136, -0.5006,  0.5798]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
      "        ...,\n",
      "        [-0.5583,  0.3698, -1.2978,  ..., -0.2742, -0.5310,  0.2084],\n",
      "        [-0.2372, -0.3621,  0.8482,  ...,  0.6932,  1.7314,  1.0317],\n",
      "        [ 0.4593,  0.0251,  0.0319,  ..., -0.0136, -0.5006,  0.5798]])\n"
     ]
    }
   ],
   "source": [
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.SentimentText)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.SentimentText).float()\n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc/ len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([28, 64])) must be the same as input size (torch.Size([64]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a1cb25f3a39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-561a59d92861>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentimentText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentimentText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrounded_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([28, 64])) must be the same as input size (torch.Size([64]))"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch in test_iterator:\n",
    "        \n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float()\n",
    "        \n",
    "        acc = correct.sum()/len(correct)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc = epoch_acc / len(test_iterator)\n",
    "\n",
    "print( test_loss:.3f, test_acc*100:.2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I hate that show\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tok.text for tok in nlp.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = [TEXT.vocab.stoi[t] for t in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.LongTensor(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.sigmoid(model(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Getting errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
